---
layout: post
category : nlp
tags : [Chinese Breaking]
---

最近闲暇时，一直在做中文分词方面的工作。虽然中文分词作为中文处理中最基础的部分，目前已经非常完善，但是在应用中，一直没有发现符合自己想法的实现！那么我想向中的分词是什么样的呢？

#中文分词
顾名思义，中文分词的主要功能是：将一段话切分成由不可再分的词构成的序列。也许看代码更清楚：

	def segment(sentence:String):List[String]

也许我们说，这样的API就可以了，按照简单的原则设计不是最好吗？可是实际情况不是这样简单，不同的应用可能需要不同的结果。

##中文分词与搜索引擎
在搜索引擎中，系统在索引和查询时都需要应用中文分词。

###构建倒排索引
构建倒排索引的时候，需要利用分词将文章切分(Tokenize)，并且需要做一些语言规范化(Linguistic Processing)相关处理。
>搜索引擎通常具备了一些语言处理的功能，但是因为不同的语言有不同的要求，所以分词不得不照顾到一些功能。

通常您可能需要考虑到的功能有：
<ul>
<li>速度快</li>  
<li>全角半角转换</li>  
<li>繁体简体转换</li>  
<li>英文及其缩写(IBM, U2)</li>  
<li>索引数字(123, 一百二十三)</li>  
<li>尽可能将词分得小(北京/市、舞蹈/家)</li>  
</ul>

索引数字可能是您需要注意的问题，不光包括中文数字转换，如果您要索引的文档中包含很多数字的化，您还得考虑无数的数字会使得搜索引擎中的关键词表的规模，这会影响系统的性能，但千万不要着急，而不索引数字。

###查询
主流搜索引擎通常都支持通配符，那么当遇到分词的时候，则不能将通配符切分。

另外，如何揣摩用户的意图，其输入的关键词当然是最重要的线索。这时候可能需要一些其它功能来辅助系统。

自定义词典或者领域词典自然不应缺少，当然还要支持同义词的功能。必要的话还应该将词切分的尽可能大一些，对有些搜索引擎而言可以返回相关性更高的结果。如果用户输入的关键词是一段话，那么分词应返回词的一些统计信息和词性，以方便程序过滤一些无意义且Posting List很长的词。

而纠错功能对搜索引擎而言自然不能缺少，那么在用户输入时，使用语音信息进行拼写检查也是必不可少的功能。
<ul>
<li>支持特殊连接字符(Glue Char)</li>  
<li>自定义词典或称领域词典</li>  
<li>同义词词典(北京市/北京)</li>  
<li>支持关键词识别</li>  
<li>拼音标注</li>  
<li>尽可能将词分得大(舞蹈家)</li>  
</ul>

##中文分词与自然语言处理
自然语言处理除了搜索引擎，还有许多其它应用，而中文分词都是其中的基础。中文分词因为这些应用的需求，也在逐步演进。例如最开始的时候，分词和词性识别通常被分成两个部分，而现在很多分词程序都将二者结合起来发布。

###文本分类和聚类
文本分类和聚类特别重要的问题之一就是特征提取。如何提取出合适的特征是非常关键的问题，常常您会发现您的语料之中有许多新词和短语，特别适合用来做特征，但是您的分词却不能将其识别成一个词。

也许有很多人会说，特别专业的词其实不一定合适用来做特征。确实，任何词必须在语料中检验之后才能决定是否适合作为特征。所以尝试一下具有新词识别的分词软件，您也许会意识到，语料库是可以动态更新的，并且特征也是需要不断更新的。

如果您处理的对象是文档，那么您一定对诸多种切分歧义很郁闷。例如：计算机会成本。如果能够利用上下文，来消除切分歧义，自是很好的，但包含歧义仍然很难消除，且速度会有一定损失。
<ul>
<li>词性标注</li>  
<li>新词识别</li>
<li>基于上下文分词</li>  
</ul>

###序列标注问题
很多自然语言处理的应用都与序列标注(Sequence Label Problem)有关。虽然分词本身也可以是一个序列标注问题，目前很多人都在推崇基于字的分词方法，不过窃以为分词可以采用多种分词方法投票。

目前仅讨论基于分词的序列标注问题。首先是分词的准确，其次是能够有更多的特征可供选择，目前常用的特征就是词和词性两种，然而对众多nlper而言，这些特征总是不够的。而且很多泰山都曾表示过，词义标注将是分词系统下一个要解决的问题。我们迫切的希望词义标注和词性识别一样，成为分词软件的标配。

联想到韩国语，一种表音的文字，一定程度上和汉语拼音相似。缺少了很多汉字，您可能会想到可以使用的特征数量变少了，是不是性能就会差一些呢？这个问题我也做了一些尝试，如果在实体识别等应用中，使用拼音替代汉字作为主要特征，那么准确率会有5%左右的下降。但是到底怎么样呢？也希望对表音文字熟悉的朋友能够告知。如果拼音去掉音调，则只有约400个，这能一程度降低模型的规模，而且对人名识别而言，“**听着像**”这个词能够很大提高系统的召回率。

<ul>
<li>词义标注</li>  
<li>拼音标注</li>  
</ul>

##中文分词程序
如果抛开以上所讨论的功能问题，从软件开发的角度看待分词，应该是怎样呢？

###资源
中文分词在系统中处于如此基础的位置，为了避免寡头垄断，支持贫民创新，开源是必要的。

词典在某些分词系统中又处于特别重要的位置，则核心词典的开放性必须要能够保证，最好是一个网络应用，可以由众多爱好者共同维护。
###软件质量
如果是开源软件，您还可以拿到源码进行代码分析，如果有足够的测试，或是基于测试驱动开发那就更好了。但是很多商用软件，其实代码质量真的不好说。总之，有足够的测试，总是让人放心的。