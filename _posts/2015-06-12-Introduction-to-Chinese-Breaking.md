---

layout: post
category : nlp
tags : [Chinese Breaking]

---
因为有同学问了关于中文分词的一些问题，很高兴，所以写了这篇博客来尝试回答。其实有现成的关于中文分词的综述！但我知道大家都懒（no offense，包括我自己），所以我就尝试简单介绍一下吧！

##中文分词的难点
翻开我两年前写的博客：<a href="http://yingrui.github.io/nlp/2013/02/15/What-Chinese-Breaking-Suppose-to-Be/">中文分词应该是什么样子</a>，发现甚难读懂（我现在写的也没有什么变化）。不过大致上还是介绍了中文分词的应用场景，功能和需求。

这篇博客回答两个问题：中文分词的难点在哪里？深度学习是什么鬼？

大家比较有共识的难点有二：
<ol>
	<li>中文句子中的歧义</li>
	<li>未登录词识别</li>
</ol>

我个人认为还有第三个难点，那就是：一千个人，就有一千种分词。有人简单统计过，如果让人来分词，即使事先已经告知分词的标准，其准确率也仅有约80%，而机器的分词准确率则比人高很多。难道能说机器比人理解得更深刻，所以切分的更好吗？所以相对不同的人来说，其实用来训练分词的语料库，都有很多错误。但是这个问题很难量化，简单来说，是要训练个性化分词器。每人一种分词，很难，目前来看大多数系统也不需要，所以这个问题没有人研究。

###中文中的歧义判别
抽象的说歧义判别有点难以理解，据两个例子就好了：
<ol>
	<li>学生物的这些曾经最优秀的学生——学生？还是生物？</li>
	<li>计算机会成本将会大大增加成功的机会——计算机？还是机会成本？</li>
	<li>乒乓球拍卖完了——乒乓球？还是乒乓球拍？</li>
	<li>化妆和服装——和服？还是服装？</li>
</ol>
以上这些都是属于交叉歧义，但是还有一种就真的很让人恼火了。他们就是包含歧义，请看：
<ol>
	<li>这个把手坏了 VS. 请把手拿开——请把手放在把手上，拧一下把手再把手放回原处！看到这句，不知道你崩溃没有？</li>
</ol>

###未登录词识别
未登录词顾名思意，就是分词程序以前没见过的词，也可以狭义的说，词典里没有的词。其中主要由以下几种构成：
<ol>
	<li>实体名称：人名、地名、机构名、产品名称等</li>
	<li>缩写和专有名词，例如：中巴建交，这里中巴也要吐槽一下，这里的巴指的是什么，巴西？巴基斯坦？巴勒斯坦？</li>
	<li>伟大的人民群众不断创造的新词：给力、宅男、双十一</li>
</ol>
那实体识别有专门的思路去解决，新词识别，也有很多思路，但是要动态的更新分词的模型。这里就不多说，因为这篇博客只是介绍分词的难点在哪里。但是专有名词和缩写，目前大多数方案都是领域词典。

###深度学习与中文分词
我们知道深度学习可以帮助我们以新的方法表示一个字或者词。例如Word2Vec将一个字或者词转换成了一个多维的向量，通常有200或300维。那么这些字就不再是一个简单的符号了，它们之间是否相似，是否相反，都通过向量之间的距离和夹角表现出来了。例如：猫、狗，这两个字的用法很相似，于是表示它们的向量也是相似的。

一、对未登录词来说，举一个简单的例子：假设“打人”是一个已有的词，但是“骂人”是一个未登录词。

在普通的分词系统中，可能要通过线下的学习，发现骂人是一个新词。然后更新词典或者模型，然后才能将骂人识别为新词。

但是在基于深度学习构建的分词系统中，如果表示打和骂的两个向量，本身是十分相近的，那极有可能，模型会自动识别出“骂人”也是一个词。

二、对于分词系统的一般性影响，也可以理解：将字由一个1维空间，映射到了高维空间，将会对分类器产生很大的积极影响。对于歧义的判别，理论上应该得到更准确的结果。
